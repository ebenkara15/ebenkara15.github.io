## Temps-réel et Big Data

![Presentation Image](docs/assets/image/front_image.png)

### De gigagntesques flux de données 

Depuis plus de 10 ans, la production et l'exploitation de données connaît une croissance vertigineuse. Si les volumes de données qui sont souvent évoqués, la nature des données est devenu très diversifiée et oblige à mettre en place de nouvelles stratégies de traitement.

A titre d'exemple, le Big Data c'est:
- Environ 50 milliards d'objets connectés dans le monde
- 150 milions de mails envoyés chaque minute
- 463 exaoctets de données générées par jour (1 exacotet = 10^9 gigaoctets)
- 2,3 millions de recherches Google chaque minute
- 70 000 heures de streaming sur Netflix chaque minute

Mais le Big Data, c'est aussi une promesse...

> La capacité à traiter des données rapidement permet de prendre les meilleures décisions

Ainsi, on a vu se développer des technologies et des infrastructures de calculs de plus en plus performantes et de moins en moins chères.


### Des évolutions technologiques

![Techno Timeline](docs/assets/image/timeline_techno.png)

Si au début du siècle, le seul traitement de données était réservé aux technologies de bases de données, l'évolution technologique permet de constater l'effort qui a été entrepris pour répondre aux besoins de stockage et de traitement croissants des données.

L'écosystème Hadoop bâtit autour du framework éponyme est le premier à proposer une solution pour le stockag et le traitement distribué. Basé sur un papier de recherche de Google, Hadoop met en oeuvre le paradigme *map-reduce*. Hadoop est aujourd'hui un pilier des architectures Big Data et un large écosystème s'est autour de la solution intiale. 

Dans un second temps, 
### Support or Contact

Having trouble with Pages? Check out our [documentation](https://docs.github.com/categories/github-pages-basics/) or [contact support](https://support.github.com/contact) and we’ll help you sort it out.
